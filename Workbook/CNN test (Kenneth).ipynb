{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c813f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2694dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine_image_paths_train = \"../Dataset/train/real\"\n",
    "genuine_image_paths_test = \"../Dataset/test/real\"\n",
    "\n",
    "forged_image_paths_train = \"../Dataset/train/forged\"\n",
    "forged_image_paths_test = \"../Dataset/test/forged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cba45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbgrey(img):\n",
    "    # Converts rgb to grayscale\n",
    "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[row])):\n",
    "            greyimg[row][col] = np.average(img[row][col])\n",
    "    return greyimg\n",
    "\n",
    "def greybin(img):\n",
    "    # Converts grayscale to binary\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
    "#     img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    binimg = np.logical_not(binimg)\n",
    "    return binimg\n",
    "\n",
    "def preproc(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    grey = rgbgrey(img) #rgb to grey\n",
    "    if display:\n",
    "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    binimg = greybin(grey) #grey to binary\n",
    "    if display:\n",
    "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(binimg==1)\n",
    "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
    "    # Thus we will get a cropped image with only the signature part.\n",
    "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return signimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673d9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total\n",
    "\n",
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]   # 1st row is the x-component, 2nd row is the y-component\n",
    "\n",
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity\n",
    "\n",
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # columns value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c21a5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal\n",
    "\n",
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])  \n",
    "    '''\n",
    "    2D MATRIX, DATA FORMAT FOR CNN INPUT. Each row vector displays each feature variable. \n",
    "    For example:\n",
    "    \n",
    "            col 1:         col 2:\n",
    "    row 0: [ratio               ]\n",
    "    row 1: [cent_y        cent_x]\n",
    "    row 2: [eccentricity        ]\n",
    "    row 3: [solidity            ]\n",
    "    row 4: [skew_y        skew_x]\n",
    "    row 5: [kurt_x        kurt_y]\n",
    "    ''' \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05c8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSV(setType):\n",
    "    # if the specified folder does not exist, create it to store the incoming CSV\n",
    "    if not(os.path.exists('../Dataset/Features')):          \n",
    "        os.mkdir('../Dataset/Features')   \n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('../Dataset/Features/Training')):\n",
    "        os.mkdir('../Dataset/Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('../Dataset/Features/Testing')):\n",
    "        os.mkdir('../Dataset/Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "   \n",
    "    # Check what type\n",
    "    if(setType != 'train' and setType != 'test'):\n",
    "        print('Invalid type!')\n",
    "        return\n",
    "    \n",
    "    if(setType == 'train'):\n",
    "        gpath = genuine_image_paths_train\n",
    "        fpath = forged_image_paths_train\n",
    "        csvpath = '../Dataset/Features/Training/training_'\n",
    "        setRange = range(1, 70)\n",
    "    else:\n",
    "        gpath = genuine_image_paths_test\n",
    "        fpath = forged_image_paths_test\n",
    "        csvpath = '../Dataset/Features/Testing/testing_'\n",
    "        setRange = range(49, 70)\n",
    "    \n",
    "\n",
    "    # Extracting features based on type defined: 'train' ranges from 1-69, 'test' ranges from 49-69\n",
    "    for person in tqdm(setRange, desc='Extracting Features...'):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "               \n",
    "        # In case folder is not iterative (i.e, 005 does not exist)\n",
    "        if not(os.path.exists(os.path.join(gpath, per))):\n",
    "            continue\n",
    "    \n",
    "        # In case folder is not iterative (i.e, 005 does not exist)\n",
    "        if not(os.path.exists(os.path.join(fpath, per+'_forg'))):\n",
    "            continue\n",
    "    \n",
    "        # every signature image will generate a unique CSV feature row specific to it, hence the concatenation\n",
    "        with open(csvpath+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "\n",
    "            # Genuine set\n",
    "            i = 1\n",
    "            fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "            filePath = os.path.join(gpath, per,  per + '_' + fileNum + '.png')\n",
    "            while(os.path.exists(filePath)):\n",
    "                source = filePath   # source image taken iteratively based on their own naming convention  \n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')  # 1 is set for genuine signatures \n",
    "                i += 1\n",
    "                fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "                filePath = os.path.join(gpath, per,  per + '_' + fileNum + '.png')\n",
    "                \n",
    "            # Forged set\n",
    "            i = 1\n",
    "            fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "            filePath = os.path.join(fpath, per+'_forg',  per + '_forg_' + fileNum + '.png')\n",
    "            while(os.path.exists(filePath)):\n",
    "                source = filePath   # source image taken iteratively based on their own naming convention  \n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')  # 0 is set for genuine signatures \n",
    "                i += 1\n",
    "                fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "                filePath = os.path.join(fpath, per+'_forg',  per + '_forg_' + fileNum + '.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b893c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(path):    # path is the image specified\n",
    "    feature = getCSVFeatures(path)   # extract features from a specific image into a tuple, suitable for storing into CSV \n",
    "    if not(os.path.exists('../Dataset/TestFeatures')):\n",
    "        os.mkdir('../Dataset/TestFeatures')\n",
    "    with open('../Dataset/TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        # create a new CSV to store the numerical features of the signature image, similar to makeCSV\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, feature))+'\\n')\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    # Reading train data\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    \n",
    "    # Reading test data\n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    \n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost < 0.0001:\n",
    "                break\n",
    "#              # Display logs per epoch step\n",
    "#             if epoch % 999 == 0:\n",
    "#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
    "#                 print(\"Optimization Finished!\")\n",
    "#                 print()        \n",
    "\n",
    "        if type2 is False:\n",
    "            # Finding accuracies\n",
    "            accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "            print(\"Accuracy for train: {0:.2f} %\".format(accuracy1*100))\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            print(\"Accuracy for test: {0:.2f} %\".format(round(accuracy2*100)))\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image: {0:.1f} %'.format(prediction[0][1]*100))\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image: {0:.1f} %'.format(prediction[0][0]*100))\n",
    "                return False\n",
    "\n",
    "\n",
    "def trainAndTest(rate=0.001, epochs=1700, neurons=7, display=False, firstPerson = 49, lastPerson = 69):    \n",
    "    start = time()\n",
    "\n",
    "    # Parameters\n",
    "    global training_rate, training_epochs, n_hidden_1\n",
    "    learning_rate = rate\n",
    "    training_epochs = epochs\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = neurons # 1st layer number of neurons\n",
    "    n_hidden_2 = 7 # 2nd layer number of neurons\n",
    "    n_hidden_3 = 30 # 3rd layer\n",
    "\n",
    "    train_avg, test_avg = 0, 0\n",
    "    n = lastPerson - firstPerson + 1\n",
    "    for i in range(firstPerson, lastPerson+1):\n",
    "        id = ('00'+str(i))[-3:]\n",
    "        if display:\n",
    "            print()\n",
    "            print(\"Running for Person id\",id)\n",
    "        train_score, test_score = evaluate(train_path.replace(('0'+str(firstPerson)),id), test_path.replace(('0'+str(firstPerson)),id))\n",
    "        train_avg += train_score\n",
    "        test_avg += test_score\n",
    "    if display:\n",
    "#         print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n",
    "        print()\n",
    "        print(\"Training average: {0:.2f}%\".format((train_avg/n)*100))\n",
    "        print(\"Testing average:{0:.2f}%\".format((test_avg/n)*100))\n",
    "        print(\"Time taken:{0:.2f}s\".format(time()-start))\n",
    "        print()\n",
    "    return train_avg/n, test_avg/n, (time()-start)\n",
    "\n",
    "# Main Menu helper function\n",
    "def printMenu():\n",
    "    print(\"Welcome to our project! Select from the options below:\")\n",
    "    print(\"[1] Upload image\")\n",
    "    print(\"[2] Run model on dataset and see accuracy\")\n",
    "    print(\"[3] Exit\")\n",
    "    \n",
    "# Test Image Helper function\n",
    "def testImage():\n",
    "    # User specifies the person id\n",
    "    i = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            i = int(input(\"Enter person's id:\"))\n",
    "        except:\n",
    "            print(\"Not a number! Try again...\")\n",
    "        else:\n",
    "            if(i<1 or i>69 or i==5 or i==7 or i==8 or i==10 or i==11):\n",
    "                print(\"Invalid choice! Try something else...\")\n",
    "            else:\n",
    "                break\n",
    "    id = ('00'+str(i))[-3:]\n",
    "    train_path = '../Dataset/Features/Training/training_'+id+'.csv'\n",
    "    \n",
    "    # User uploads their own image\n",
    "    root = Tk()\n",
    "    root.title('Upload Your Signature')\n",
    "    root.resizable(False, False)\n",
    "    root.geometry('300x150')\n",
    "    \n",
    "    # Select File helper function\n",
    "    def select_file():\n",
    "        filetypes = (('PNG files', '*.png'), ('All files', '*.*'))\n",
    "        filename = askopenfilename(title='Open a file', filetypes=filetypes)                      \n",
    "        # Use CNN model to predict\n",
    "        testing(filename)\n",
    "        test_path = '../Dataset/TestFeatures/testcsv.csv'\n",
    "        evaluate(train_path, test_path, type2=True)\n",
    "        root.destroy()\n",
    "        \n",
    "    open_button = Button(root, text='Open a File', command=select_file).pack(expand=True)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8fae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 9\n",
    "# key in path of image that you want to check (eg: ../Dataset/test/forged/049_forg/049_forg_01.png):\n",
    "train_path = '../Dataset/Features/Training/training_049.csv' # specify path of train CSV for that requested person\n",
    "test_path = '../Dataset/Features/Testing/testing_049.csv'  # specify the path of newly created test CSV\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 7 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "n_hidden_3 = 30 # 3rd layer number of neurons\n",
    "n_classes = 2 # no. of classes (genuine or forged)\n",
    "\n",
    "# tf Graph input\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.math.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op, var_list=None)\n",
    "\n",
    "# For accuracies\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "010b48f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our project! Select from the options below:\n",
      "[1] Upload image\n",
      "[2] Run model on dataset and see accuracy\n",
      "[3] Exit\n",
      "Enter your choice:1\n",
      "Enter person's id:1\n",
      "Forged Image: 71.2 %\n",
      "\n",
      "Welcome to our project! Select from the options below:\n",
      "[1] Upload image\n",
      "[2] Run model on dataset and see accuracy\n",
      "[3] Exit\n",
      "Enter your choice:3\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Main portion\n",
    "printMenu()\n",
    "choice = -1\n",
    "while(True):\n",
    "    # Input validation\n",
    "    try:\n",
    "        choice = int(input(\"Enter your choice:\"))\n",
    "        if(choice < 1 or choice > 3):\n",
    "            print(\"Invalid choice! Try again...\")\n",
    "            print()\n",
    "            continue\n",
    "    except:\n",
    "        print(\"Something went wrong, try again...\")\n",
    "    else: \n",
    "        # User selection\n",
    "        if choice == 1:\n",
    "            testImage()\n",
    "        elif choice == 2:\n",
    "            trainAndTest(display=True)\n",
    "        else:\n",
    "            print(\"Goodbye!\")\n",
    "            break;\n",
    "        print()\n",
    "        printMenu()\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d658e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
