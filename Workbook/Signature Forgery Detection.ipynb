{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed476dfd",
   "metadata": {},
   "source": [
    "# SC1015 Mini Project: Signature Forgery Detection\n",
    "\n",
    "  Welcome to our mini project! This first section will run you through the overview of what our project is about. We decided to follow the Datapipeline taught to us in the DataScience portion of this module: \n",
    "  \n",
    "  1. __Practical Motivation:__ Why do we choose this problem?\n",
    "  2. __Sample Collection:__ Which dataset do we use?\n",
    "  3. __Problem Formulation:__ Rephrasing the problem into a datascience problem\n",
    "  4. __Data Preparation:__ Steps needed to setup the dataset\n",
    "  5. __Statistical Description:__ Statistics to describe our input data\n",
    "  6. __Exploratory Analysis:__ What can we analyse from the statistics of our data?\n",
    "  7. __Pattern Recognition:__ What patterns/features can we find from our data?\n",
    "  8. __Analytic Visualization:__ How can we visualise what we're working with?\n",
    "  9. __Machine Learning:__ Which model do we use to solve our problem?\n",
    "  10. __Algorithmic Optimization:__ How can we optimise our algorithm? \n",
    "  11. __Statistical Inference:__ What can we infer from the results?\n",
    "  12. __Information Presentation:__ Side by side comparison of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36300f",
   "metadata": {},
   "source": [
    "## Imports\n",
    "  The section below will import all the necessary libraries for this project. Although, there are some pre-requisites needed to install into your python CMD or anaconda CMD. \n",
    "  \n",
    "  * __pip install \"tensorflow<2.11\"__\n",
    "  * __pip install opencv-python__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e04006",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/h0pwj9_d6w1_95cqd2tl4x800000gn/T/ipykernel_48939/2907709602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreshold_otsu\u001b[0m   \u001b[0;31m# For finding the threshold for grayscale to binary conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "import cv2 \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a99f7",
   "metadata": {},
   "source": [
    "## Practical Motivation\n",
    "  Signature forgery is a problem that bypasses an untrained eye. Not everyone has the patience to meticulously check the authenticity of thousands of documents. In fact, a Singaporean man was able to forge documents that helped him get 38 jobs in 4 years ([CNA](https://www.channelnewsasia.com/singapore/man-forge-documents-nus-degree-get-jobs-38-companies-890881), 2019). \n",
    "  ![Signature Forgery](https://www.martypearce.com/wp-content/uploads/2019/01/3e406f_00f3feb43e17449c8bfacc0f850bf362mv2.jpg)\n",
    "  Forgery is a real concern and humans are bound to make mistakes when checking for forged documents. On a tiring day, we may not always be able to find forged documents and so our group strives to build a working model that can consistently detect Signature Forgery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112a3ac",
   "metadata": {},
   "source": [
    "## Sample Collection\n",
    "  The dataset we will be using is from Kaggle: [https://www.kaggle.com/datasets/robinreni/signature-verification-dataset](https://www.kaggle.com/datasets/robinreni/signature-verification-dataset). \n",
    "  It has the following directory:\n",
    "* sign_data\n",
    "  * test\n",
    "  * train\n",
    "  * test_data.csv\n",
    "  * train_data.csv\n",
    "  \n",
    "  \n",
    "1. There are a total of 2,149 images(png)\n",
    "2. A training set of 69 different individuals' signatures, separated into a genuine and forged set of images\n",
    "3. A test set of 21 different individuals' signatures, separated into a genuine and forged set of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3b5dd",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "  In terms of Data Science, this is definitely a \"Classification\" type of problem and we will be working with unstructured data, namely images. If we were to phrase this problem we would ask:\n",
    "  \n",
    "  __Is this image a genuine or forged signature?__\n",
    "  \n",
    "  This is a binary type of classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2aa60",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we start with the analyses of the dataset, we first restructure the folder layout of the dataset.\n",
    "\n",
    "### **Before** \n",
    "```\n",
    "Root_Folder\n",
    "└── Dataset/\n",
    "    ├── test/\n",
    "    │   ├── 049/\n",
    "    │   │   ├── 01_049.png\n",
    "    │   │   ├── 02_049.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 049_forg/\n",
    "    │   │   ├── 01_0114049.png\n",
    "    │   │   ├── 01_0206049.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 050/\n",
    "    │   ├── 050_forg/\n",
    "    │   └── ...\n",
    "    ├── train/\n",
    "    │   ├── 001/\n",
    "    │   │   ├── 001_01.png\n",
    "    │   │   ├── 001_02.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 001_forg/\n",
    "    │   │   ├── 0119001_01.png\n",
    "    │   │   ├── 0119001_02.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 002/\n",
    "    │   ├── 002_forg/\n",
    "    │   └── ...\n",
    "    ├── test_data.csv\n",
    "    └── train_data.csv\n",
    "```\n",
    "\n",
    "### **After**\n",
    "```\n",
    "Root_Folder\n",
    "└── Dataset/\n",
    "    ├── test/\n",
    "    │   ├── forged/\n",
    "    │   │   ├── 049_forg/\n",
    "    │   │   │   ├── 049_forg_01.png\n",
    "    │   │   │   ├── 049_forg_02.png\n",
    "    │   │   │   └── ...\n",
    "    │   │   ├── 050_forg/\n",
    "    │   │   ├── 051_forg/\n",
    "    │   │   └── ...\n",
    "    │   └── real/\n",
    "    │       ├── 049/\n",
    "    │       │   ├── 01_049.png\n",
    "    │       │   ├── 02_049.png\n",
    "    │       │   └── ...\n",
    "    │       ├── 050/\n",
    "    │       ├── 051/\n",
    "    │       └── ...\n",
    "    ├── train/\n",
    "    │   ├── forged/\n",
    "    │   │   ├── 001_forg/\n",
    "    │   │   │   ├── 001_forg_01.png\n",
    "    │   │   │   ├── 001_forg_02.png\n",
    "    │   │   │   └── ...\n",
    "    │   │   ├── 002_forg/\n",
    "    │   │   └── ...\n",
    "    │   └── real/\n",
    "    │       ├── 001/\n",
    "    │       │   ├── 001_01.png\n",
    "    │       │   ├── 001_02.png\n",
    "    │       │   └── ...\n",
    "    │       ├── 002/\n",
    "    │       └── ...\n",
    "    ├── test_data.csv\n",
    "    └── train_data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57ac68",
   "metadata": {},
   "source": [
    "We added 2 folders(real & forged) in each **train** and **test** folders to categorise the signatures for better access.\n",
    "\n",
    "Next, we moved on to actual preparation of the data. As the data is already split into **train** and **test** set, we do not need further splitting of the data.\n",
    "\n",
    "Additionally, no data cleaning is required as the images does not contain any noises(images are high definition of different signatures). Also, all the signatures have the been categorised based on the individuals, no further classifying the images is needed.\n",
    "\n",
    "However, one thing we need to do is to convert the image into numerical value to do processing on the data extracted.\n",
    "\n",
    "We have come up with 2 ways to convert the images into numerical values\n",
    "\n",
    "    1) Converting images into 2D array of RGB values\n",
    "\n",
    "    2) Converting images into different properties (will be covered more in depth later)\n",
    "\n",
    "These 2 approaches will be used in the different solutions to address our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c8707",
   "metadata": {},
   "source": [
    "### Image Conversion Method 1 - Converting images into 2D array of RGB Values. \n",
    "\n",
    "This is done using existing library (`cv2`) to read the image (`imread`) and convert them into RGB values\n",
    "\n",
    "A detailed example is shown below\n",
    "\n",
    "```python\n",
    "img = cv2.imread(*filename*)\n",
    "\"\"\"\n",
    "Example value of img:\n",
    "\n",
    "[[250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]\n",
    " ...\n",
    " [250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]]\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "However, as our images are of different dimensions, we would need to resize/scale the images so that there are of the same dimensions. An example of the scaling function is shown below\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "imageA: RGB values of first image\n",
    "imageB: RGB values of second image\n",
    "return: RGB values of both image A and image B\n",
    "\n",
    "The function check for the smaller dimension \n",
    "of the images and scale up the smaller one \n",
    "to the dimension of the bigger one\n",
    "\"\"\"\n",
    "def image_resize(imageA, imageB):\n",
    "    if not (imageA.shape == imageB.shape):\n",
    "        # Scale the smaller dimension pictures\n",
    "        if (imageA.shape < imageB.shape):\n",
    "            dim = (imageB.shape[1], imageB.shape[0])\n",
    "            imageA = cv2.resize(imageA, dim)\n",
    "        elif (imageB.shape < imageA.shape):\n",
    "            dim = (imageA.shape[1], imageA.shape[0])\n",
    "            imageB = cv2.resize(imageB, dim)\n",
    "        \n",
    "    return imageA, imageB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0be32b",
   "metadata": {},
   "source": [
    "## Statistical Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017fa9e",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19b8c5",
   "metadata": {},
   "source": [
    "## Pattern Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b187a18",
   "metadata": {},
   "source": [
    "## Analytic Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87e36e",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570694f4",
   "metadata": {},
   "source": [
    "## Algorithmic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974783f2",
   "metadata": {},
   "source": [
    "## Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0088acd",
   "metadata": {},
   "source": [
    "## Information Presentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
