{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed476dfd",
   "metadata": {},
   "source": [
    "# SC1015 Mini Project: Signature Forgery Detection\n",
    "\n",
    "  Welcome to our mini project! This first section will run you through the overview of what our project is about. We decided to follow the Datapipeline taught to us in the DataScience portion of this module: \n",
    "  \n",
    "  1. __Practical Motivation:__ Why do we choose this problem?\n",
    "  2. __Sample Collection:__ Which dataset do we use?\n",
    "  3. __Problem Formulation:__ Rephrasing the problem into a datascience problem\n",
    "  4. __Data Preparation:__ Steps needed to setup the dataset\n",
    "  5. __Statistical Description:__ Statistics to describe our input data\n",
    "  6. __Exploratory Analysis:__ What can we analyse from the statistics of our data?\n",
    "  7. __Pattern Recognition:__ What patterns/features can we find from our data?\n",
    "  8. __Analytic Visualization:__ How can we visualise what we're working with?\n",
    "  9. __Machine Learning:__ Which model do we use to solve our problem?\n",
    "  10. __Algorithmic Optimization:__ How can we optimise our algorithm? \n",
    "  11. __Statistical Inference:__ What can we infer from the results?\n",
    "  12. __Information Presentation:__ Side by side comparison of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36300f",
   "metadata": {},
   "source": [
    "## Imports\n",
    "  The section below will import all the necessary libraries for this project. Although, there are some pre-requisites needed to install into your python CMD or anaconda CMD. \n",
    "  \n",
    "  * __pip install \"tensorflow<2.11\"__\n",
    "  * __pip install opencv-python__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e04006",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/h0pwj9_d6w1_95cqd2tl4x800000gn/T/ipykernel_48939/2907709602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreshold_otsu\u001b[0m   \u001b[0;31m# For finding the threshold for grayscale to binary conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "import cv2 \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a99f7",
   "metadata": {},
   "source": [
    "## Practical Motivation\n",
    "  Signature forgery is a problem that bypasses an untrained eye. Not everyone has the patience to meticulously check the authenticity of thousands of documents. In fact, a Singaporean man was able to forge documents that helped him get 38 jobs in 4 years ([CNA](https://www.channelnewsasia.com/singapore/man-forge-documents-nus-degree-get-jobs-38-companies-890881), 2019). \n",
    "  ![Signature Forgery](https://www.martypearce.com/wp-content/uploads/2019/01/3e406f_00f3feb43e17449c8bfacc0f850bf362mv2.jpg)\n",
    "  Forgery is a real concern and humans are bound to make mistakes when checking for forged documents. On a tiring day, we may not always be able to find forged documents and so our group strives to build a working model that can consistently detect Signature Forgery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112a3ac",
   "metadata": {},
   "source": [
    "## Sample Collection\n",
    "  The dataset we will be using is from Kaggle: [https://www.kaggle.com/datasets/robinreni/signature-verification-dataset](https://www.kaggle.com/datasets/robinreni/signature-verification-dataset). \n",
    "  It has the following directory:\n",
    "* sign_data\n",
    "  * test\n",
    "  * train\n",
    "  * test_data.csv\n",
    "  * train_data.csv\n",
    "  \n",
    "  \n",
    "1. There are a total of 2,149 images(png)\n",
    "2. A training set of 69 different individuals' signatures, separated into a genuine and forged set of images\n",
    "3. A test set of 21 different individuals' signatures, separated into a genuine and forged set of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3b5dd",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "  In terms of Data Science, this is definitely a \"Classification\" type of problem and we will be working with unstructured data, namely images. If we were to phrase this problem we would ask:\n",
    "  \n",
    "  __Is this image a genuine or forged signature?__\n",
    "  \n",
    "  This is a binary type of classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2aa60",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we start with the analyses of the dataset, we first restructure the folder layout of the dataset.\n",
    "\n",
    "### **Before** \n",
    "```\n",
    "Root_Folder\n",
    "└── Dataset/\n",
    "    ├── test/\n",
    "    │   ├── 049/\n",
    "    │   │   ├── 01_049.png\n",
    "    │   │   ├── 02_049.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 049_forg/\n",
    "    │   │   ├── 01_0114049.png\n",
    "    │   │   ├── 01_0206049.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 050/\n",
    "    │   ├── 050_forg/\n",
    "    │   └── ...\n",
    "    ├── train/\n",
    "    │   ├── 001/\n",
    "    │   │   ├── 001_01.png\n",
    "    │   │   ├── 001_02.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 001_forg/\n",
    "    │   │   ├── 0119001_01.png\n",
    "    │   │   ├── 0119001_02.png\n",
    "    │   │   └── ...\n",
    "    │   ├── 002/\n",
    "    │   ├── 002_forg/\n",
    "    │   └── ...\n",
    "    ├── test_data.csv\n",
    "    └── train_data.csv\n",
    "```\n",
    "\n",
    "### **After**\n",
    "```\n",
    "Root_Folder\n",
    "└── Dataset/\n",
    "    ├── test/\n",
    "    │   ├── forged/\n",
    "    │   │   ├── 049_forg/\n",
    "    │   │   │   ├── 049_forg_01.png\n",
    "    │   │   │   ├── 049_forg_02.png\n",
    "    │   │   │   └── ...\n",
    "    │   │   ├── 050_forg/\n",
    "    │   │   ├── 051_forg/\n",
    "    │   │   └── ...\n",
    "    │   └── real/\n",
    "    │       ├── 049/\n",
    "    │       │   ├── 01_049.png\n",
    "    │       │   ├── 02_049.png\n",
    "    │       │   └── ...\n",
    "    │       ├── 050/\n",
    "    │       ├── 051/\n",
    "    │       └── ...\n",
    "    ├── train/\n",
    "    │   ├── forged/\n",
    "    │   │   ├── 001_forg/\n",
    "    │   │   │   ├── 001_forg_01.png\n",
    "    │   │   │   ├── 001_forg_02.png\n",
    "    │   │   │   └── ...\n",
    "    │   │   ├── 002_forg/\n",
    "    │   │   └── ...\n",
    "    │   └── real/\n",
    "    │       ├── 001/\n",
    "    │       │   ├── 001_01.png\n",
    "    │       │   ├── 001_02.png\n",
    "    │       │   └── ...\n",
    "    │       ├── 002/\n",
    "    │       └── ...\n",
    "    ├── test_data.csv\n",
    "    └── train_data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581710cd",
   "metadata": {},
   "source": [
    "We added 2 folders(real & forged) in each **train** and **test** folders to categorise the signatures for better access.\n",
    "\n",
    "Next, we moved on to actual preparation of the data. As the data is already split into **train** and **test** set, we do not need further splitting of the data.\n",
    "\n",
    "Additionally, no data cleaning is required as the images does not contain any noises(images are high definition of different signatures). Also, all the signatures have the been categorised based on the individuals, no further classifying the images is needed.\n",
    "\n",
    "However, one thing we need to do is to convert the image into numerical value to do processing on the data extracted.\n",
    "\n",
    "We have come up with 2 ways to convert the images into numerical values\n",
    "\n",
    "    1) Converting images into 2D array of RGB values\n",
    "\n",
    "    2) Converting images into different properties (will be covered more in depth later)\n",
    "\n",
    "These 2 approaches will be used in the different solutions to address our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811018a",
   "metadata": {},
   "source": [
    "### Image Conversion Method 1 - Converting images into 2D array of RGB Values. \n",
    "\n",
    "This is done using existing library (`cv2`) to read the image (`imread`) and convert them into RGB values\n",
    "\n",
    "A detailed example is shown below\n",
    "\n",
    "```python\n",
    "img = cv2.imread(*filename*)\n",
    "\"\"\"\n",
    "Example value of img:\n",
    "\n",
    "[[250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]\n",
    " ...\n",
    " [250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]\n",
    " [250 250 250 ... 250 250 250]]\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "However, as our images are of different dimensions, we would need to resize/scale the images so that there are of the same dimensions. An example of the scaling function is shown below.\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "imageA: RGB values of first image\n",
    "imageB: RGB values of second image\n",
    "return: RGB values of both image A and image B\n",
    "\n",
    "The function check for the smaller dimension \n",
    "of the images and scale up the smaller one \n",
    "to the dimension of the bigger one\n",
    "\"\"\"\n",
    "def image_resize(imageA, imageB):\n",
    "    if not (imageA.shape == imageB.shape):\n",
    "        # Scale the smaller dimension pictures\n",
    "        if (imageA.shape < imageB.shape):\n",
    "            dim = (imageB.shape[1], imageB.shape[0])\n",
    "            imageA = cv2.resize(imageA, dim)\n",
    "        elif (imageB.shape < imageA.shape):\n",
    "            dim = (imageA.shape[1], imageA.shape[0])\n",
    "            imageB = cv2.resize(imageB, dim)\n",
    "        \n",
    "    return imageA, imageB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0be32b",
   "metadata": {},
   "source": [
    "## Statistical Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82325f24",
   "metadata": {},
   "source": [
    "### Feature extraction - Converting the preprocessed images into numbers and statistics that can be inputed into our CNN model. This data invokes the concept of clustering to classify data according to certain patterns. In this case, the patterns are the distinct features of a signature, namely:\n",
    "\n",
    "##### ratio: The ratio of the width to height of the bounding box around the signature.\n",
    "##### cent_y: The y-coordinate of the center of mass of the signature.\n",
    "##### cent_x: The x-coordinate of the center of mass of the signature.\n",
    "##### eccentricity: A measure of how elongated the signature is.\n",
    "##### solidity: The ratio of the area of the signature to the area of the convex hull surrounding it.\n",
    "##### skew_x: A measure of how asymmetric the signature is with respect to the x-axis.\n",
    "##### skew_y: A measure of how asymmetric the signature is with respect to the y-axis.\n",
    "##### kurt_x: A measure of how heavy the tails of the signature are with respect to the x-axis.\n",
    "##### kurt_y: A measure of how heavy the tails of the signature are with respect to the y-axis.\n",
    "##### The outputs '0' and '1' indicate whether the signature is genuine or forged, with '1' representing a genuine signature and '0' representing a forged signature.\n",
    "\n",
    "### For our specific case, instead of classifying data into specific categories, we use numeric metrics to quantify how much of that particular feature that signature possesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0633475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]   # 1st row is the x-component, 2nd row is the y-component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b92224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # columns value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10de2591",
   "metadata": {},
   "source": [
    "#### getFeatures function extracts the numerical values of the various features, and returns the data in the form of a tuple\n",
    "\n",
    "#### getCSVFeatures uses this tuple and converts it into a 2-dimensional matrix as input format for CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])  \n",
    "    '''\n",
    "    2D MATRIX, DATA FORMAT FOR CNN INPUT. Each row vector displays each feature variable. \n",
    "    For example:\n",
    "    \n",
    "            col 1:         col 2:\n",
    "    row 0: [ratio               ]\n",
    "    row 1: [cent_y        cent_x]\n",
    "    row 2: [eccentricity        ]\n",
    "    row 3: [solidity            ]\n",
    "    row 4: [skew_y        skew_x]\n",
    "    row 5: [kurt_x        kurt_y]\n",
    "    ''' \n",
    "    return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad8954d5",
   "metadata": {},
   "source": [
    "### Saving the features\n",
    "\n",
    "##### Saves the numerical variables of the signatures into an Excel CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4623eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSV(setType):\n",
    "    # if the specified folder does not exist, create it to store the incoming CSV\n",
    "    if not(os.path.exists('../Dataset/Features')):          \n",
    "        os.mkdir('../Dataset/Features')   \n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('../Dataset/Features/Training')):\n",
    "        os.mkdir('../Dataset/Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('../Dataset/Features/Testing')):\n",
    "        os.mkdir('../Dataset/Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "   \n",
    "    # Check what type\n",
    "    if(setType != 'train' and setType != 'test'):\n",
    "        print('Invalid type!')\n",
    "        return\n",
    "    \n",
    "    if(setType == 'train'):\n",
    "        gpath = genuine_image_paths_train\n",
    "        fpath = forged_image_paths_train\n",
    "        csvpath = '../Dataset/Features/Training/training_'\n",
    "        setRange = range(1, 70)\n",
    "    else:\n",
    "        gpath = genuine_image_paths_test\n",
    "        fpath = forged_image_paths_test\n",
    "        csvpath = '../Dataset/Features/Testing/testing_'\n",
    "        setRange = range(49, 70)\n",
    "    \n",
    "\n",
    "    # Extracting features based on type defined: 'train' ranges from 1-69, 'test' ranges from 49-69\n",
    "    for person in tqdm(setRange, desc='Extracting Features...'):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "               \n",
    "        # In case folder is not iterative (i.e, 005 does not exist)\n",
    "        if not(os.path.exists(os.path.join(gpath, per))):\n",
    "            continue\n",
    "    \n",
    "        # In case folder is not iterative (i.e, 005 does not exist)\n",
    "        if not(os.path.exists(os.path.join(fpath, per+'_forg'))):\n",
    "            continue\n",
    "    \n",
    "        # every signature image will generate a unique CSV feature row specific to it, hence the concatenation\n",
    "        with open(csvpath+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "\n",
    "            # Genuine set\n",
    "            i = 1\n",
    "            fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "            filePath = os.path.join(gpath, per,  per + '_' + fileNum + '.png')\n",
    "            while(os.path.exists(filePath)):\n",
    "                source = filePath   # source image taken iteratively based on their own naming convention  \n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')  # 1 is set for genuine signatures \n",
    "                i += 1\n",
    "                fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "                filePath = os.path.join(gpath, per,  per + '_' + fileNum + '.png')\n",
    "                \n",
    "            # Forged set\n",
    "            i = 1\n",
    "            fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "            filePath = os.path.join(fpath, per+'_forg',  per + '_forg_' + fileNum + '.png')\n",
    "            while(os.path.exists(filePath)):\n",
    "                source = filePath   # source image taken iteratively based on their own naming convention  \n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')  # 0 is set for genuine signatures \n",
    "                i += 1\n",
    "                fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "                filePath = os.path.join(fpath, per+'_forg',  per + '_forg_' + fileNum + '.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New folder \"Features\" created\n",
      "New folder \"Features/Training\" created\n",
      "New folder \"Features/Testing\" created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features...: 100%|██████████████████████████████████████████████████████████| 69/69 [59:31<00:00, 51.76s/it]\n",
      "Extracting Features...: 100%|██████████████████████████████████████████████████████████| 21/21 [20:17<00:00, 57.96s/it]\n"
     ]
    }
   ],
   "source": [
    "makeCSV('train')\n",
    "makeCSV('test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c219089e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e017fa9e",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19b8c5",
   "metadata": {},
   "source": [
    "## Pattern Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b187a18",
   "metadata": {},
   "source": [
    "## Analytic Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87e36e",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570694f4",
   "metadata": {},
   "source": [
    "## Algorithmic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974783f2",
   "metadata": {},
   "source": [
    "## Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0088acd",
   "metadata": {},
   "source": [
    "## Information Presentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
