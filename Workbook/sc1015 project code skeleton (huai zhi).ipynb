{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2d796f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_5/h0pwj9_d6w1_95cqd2tl4x800000gn/T/ipykernel_8315/376980940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreshold_otsu\u001b[0m   \u001b[0;31m# For finding the threshold for grayscale to binary conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03dfd3c",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Path defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1170b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine_image_paths_train = \"../Dataset/train/real\"\n",
    "genuine_image_paths_test = \"../Dataset/test/real\"\n",
    "\n",
    "forged_image_paths_train = \"../Dataset/train/forged\"\n",
    "forged_image_paths_test = \"../Dataset/test/forged\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda451c",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Preparation - necessary steps to prepare the raw data, e.g. cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a4240",
   "metadata": {},
   "source": [
    "#### Pre-processing the images: Converting the format of the PNG images from\n",
    "#### 1. RGB to Greyscale\n",
    "#### 2. Greyscale to Binary\n",
    "\n",
    "### This is to decrease the number of variables to work with, now that the images are composed of elements that are definitely either black or white. This pronounces the edges and curves of the signature by delineating clearly what is inked and what is not, making feature extraction more conclusive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea50bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbgrey(img):\n",
    "    # Converts rgb to grayscale\n",
    "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[row])):\n",
    "            greyimg[row][col] = np.average(img[row][col])\n",
    "    return greyimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81bb0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greybin(img):\n",
    "    # Converts grayscale to binary\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
    "#     img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    binimg = np.logical_not(binimg)\n",
    "    return binimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "061931fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    grey = rgbgrey(img) #rgb to grey\n",
    "    if display:\n",
    "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    binimg = greybin(grey) #grey to binary\n",
    "    if display:\n",
    "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(binimg==1)\n",
    "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
    "    # Thus we will get a cropped image with only the signature part.\n",
    "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return signimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88fc0f",
   "metadata": {},
   "source": [
    "## Statistical Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301b483",
   "metadata": {},
   "source": [
    "### Feature extraction - Converting the preprocessed images into numbers and statistics that can be inputed into our CNN model. This data invokes the concept of clustering to classify data according to certain patterns. In this case, the patterns are the distinct features of a signature, namely:\n",
    "\n",
    "#### ratio: The ratio of the width to height of the bounding box around the signature.\n",
    "#### cent_y: The y-coordinate of the center of mass of the signature.\n",
    "#### cent_x: The x-coordinate of the center of mass of the signature.\n",
    "#### eccentricity: A measure of how elongated the signature is.\n",
    "#### solidity: The ratio of the area of the signature to the area of the convex hull surrounding it.\n",
    "#### skew_x: A measure of how asymmetric the signature is with respect to the x-axis.\n",
    "#### skew_y: A measure of how asymmetric the signature is with respect to the y-axis.\n",
    "#### kurt_x: A measure of how heavy the tails of the signature are with respect to the x-axis.\n",
    "#### kurt_y: A measure of how heavy the tails of the signature are with respect to the y-axis.\n",
    "#### The outputs '0' and '1' indicate whether the signature is genuine or forged, with '1' representing a genuine signature and '0' representing a forged signature.\n",
    "\n",
    "### For our specific case, instead of classifying data into specific categories, we use numeric metrics to quantify how much of that particular feature that signature possesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07a9496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e0e41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]   # 1st row is the x-component, 2nd row is the y-component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59544409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fedc2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # columns value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653cd76",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### getFeatures function extracts the numerical values of the various features, and returns the data in the form of a tuple\n",
    "\n",
    "### getCSVFeatures uses this tuple and converts it into a 2-dimensional matrix as input format for CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "752d15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "247a6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])  \n",
    "    '''\n",
    "    2D MATRIX, DATA FORMAT FOR CNN INPUT. Each row vector displays each feature variable. \n",
    "    For example:\n",
    "    \n",
    "            col 1:         col 2:\n",
    "    row 0: [ratio               ]\n",
    "    row 1: [cent_y        cent_x]\n",
    "    row 2: [eccentricity        ]\n",
    "    row 3: [solidity            ]\n",
    "    row 4: [skew_y        skew_x]\n",
    "    row 5: [kurt_x        kurt_y]\n",
    "    ''' \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa959fb",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving the features\n",
    "\n",
    "#### Saves the numerical variables of the signatures into an Excel CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c01ac998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSV(setType):\n",
    "    # if the specified folder does not exist, create it to store the incoming CSV\n",
    "    if not(os.path.exists('../Dataset/Features')):          \n",
    "        os.mkdir('../Dataset/Features')   \n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('../Dataset/Features/Training')):\n",
    "        os.mkdir('../Dataset/Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('../Dataset/Features/Testing')):\n",
    "        os.mkdir('../Dataset/Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "   \n",
    "    # Check what type\n",
    "    if(setType != 'train' and setType != 'test'):\n",
    "        print('Invalid type!')\n",
    "        return\n",
    "    \n",
    "    if(setType == 'train'):\n",
    "        gpath = genuine_image_paths_train\n",
    "        fpath = forged_image_paths_train\n",
    "        csvpath = '../Dataset/Features/Training/training_'\n",
    "        setRange = range(1, 70)\n",
    "    else:\n",
    "        gpath = genuine_image_paths_test\n",
    "        fpath = forged_image_paths_test\n",
    "        csvpath = '../Dataset/Features/Testing/testing_'\n",
    "        setRange = range(49, 70)\n",
    "    \n",
    "\n",
    "    # Extracting features based on type defined: 'train' ranges from 1-69, 'test' ranges from 49-69\n",
    "    for person in tqdm(setRange, desc='Extracting Features...'):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "               \n",
    "        # In case folder is not iterative (i.e, 005 does not exist)\n",
    "        if not(os.path.exists(os.path.join(gpath, per))):\n",
    "            continue\n",
    "    \n",
    "        # In case folder is not iterative (i.e, 005 does not exist)\n",
    "        if not(os.path.exists(os.path.join(fpath, per+'_forg'))):\n",
    "            continue\n",
    "    \n",
    "        # every signature image will generate a unique CSV feature row specific to it, hence the concatenation\n",
    "        with open(csvpath+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "\n",
    "            # Genuine set\n",
    "            i = 1\n",
    "            fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "            filePath = os.path.join(gpath, per,  per + '_' + fileNum + '.png')\n",
    "            while(os.path.exists(filePath)):\n",
    "                source = filePath   # source image taken iteratively based on their own naming convention  \n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')  # 1 is set for genuine signatures \n",
    "                i += 1\n",
    "                fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "                filePath = os.path.join(gpath, per,  per + '_' + fileNum + '.png')\n",
    "                \n",
    "            # Forged set\n",
    "            i = 1\n",
    "            fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "            filePath = os.path.join(fpath, per+'_forg',  per + '_forg_' + fileNum + '.png')\n",
    "            while(os.path.exists(filePath)):\n",
    "                source = filePath   # source image taken iteratively based on their own naming convention  \n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')  # 0 is set for genuine signatures \n",
    "                i += 1\n",
    "                fileNum = ('0' + str(i))[-2:]  # this takes care of single vs double digits\n",
    "                filePath = os.path.join(fpath, per+'_forg',  per + '_forg_' + fileNum + '.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d46eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2040c440",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmakeCSV\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m makeCSV(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mmakeCSV\u001b[1;34m(setType)\u001b[0m\n\u001b[0;32m     27\u001b[0m     setRange \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m49\u001b[39m, \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Extracting features based on type defined: 'train' ranges from 1-69, 'test' ranges from 49-69\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(setRange, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting Features...\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     32\u001b[0m     per \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(person))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# In case folder is not iterative (i.e, 005 does not exist)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "makeCSV('train')\n",
    "makeCSV('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ec3cc",
   "metadata": {},
   "source": [
    "# CNN Model via TensorFlow\n",
    "\n",
    "\n",
    "#### ALL HELPER FUNCTIONS:\n",
    "\n",
    "##### testing() function to make a new seperate CSV to store the features of the specific test image. Might be redundant if we are only using an existing test set, but this is to cover the scenario of custom external images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0806294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(path):    # path is the image specified\n",
    "    feature = getCSVFeatures(path)   # extract features from a specific image into a tuple, suitable for storing into CSV \n",
    "    if not(os.path.exists('../Dataset/TestFeatures')):\n",
    "        os.mkdir('../Dataset/TestFeatures')\n",
    "    with open('../Dataset/TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        # create a new CSV to store the numerical features of the signature image, similar to makeCSV\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, feature))+'\\n')\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    # Reading train data\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    \n",
    "    # Reading test data\n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    \n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost < 0.0001:\n",
    "                break\n",
    "#              # Display logs per epoch step\n",
    "#             if epoch % 999 == 0:\n",
    "#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
    "#                 print(\"Optimization Finished!\")\n",
    "#                 print()\n",
    "        \n",
    "#         # Finding accuracies\n",
    "#         accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "#         print(\"Accuracy for train:\", accuracy1)\n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            print(\"Accuracy for test:\", accuracy2)\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image: {0:.1f} %'.format(prediction[0][1]*100))\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image: {0:.1f} %'.format(prediction[0][0]*100))\n",
    "                return False\n",
    "\n",
    "\n",
    "def trainAndTest(rate=0.001, epochs=1700, neurons=7, display=False):    \n",
    "    start = time()\n",
    "\n",
    "    # Parameters\n",
    "    global training_rate, training_epochs, n_hidden_1\n",
    "    learning_rate = rate\n",
    "    training_epochs = epochs\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = neurons # 1st layer number of neurons\n",
    "    n_hidden_2 = 7 # 2nd layer number of neurons\n",
    "    n_hidden_3 = 30 # 3rd layer\n",
    "\n",
    "    train_avg, test_avg = 0, 0\n",
    "    n = 10\n",
    "    for i in range(1,n+1):\n",
    "        if display:\n",
    "            print(\"Running for Person id\",i)\n",
    "        temp = ('0'+str(i))[-2:]\n",
    "        train_score, test_score = evaluate(train_path.replace('01',temp), test_path.replace('01',temp))\n",
    "        train_avg += train_score\n",
    "        test_avg += test_score\n",
    "    if display:\n",
    "#         print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n",
    "        print(\"Training average-\", train_avg/n)\n",
    "        print(\"Testing average-\", test_avg/n)\n",
    "        print(\"Time taken-\", time()-start)\n",
    "    return train_avg/n, test_avg/n, (time()-start)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e28e3eeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter person's id : 069\n",
      "Enter path of signature image : ../Dataset/test/forged/069_forg/069_forg_01.png\n",
      "Forged Image: 73.8 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = 9\n",
    "train_person_id = input(\"Enter person's id : \")  # eg: 049\n",
    "# key in path of image that you want to check (eg: ../Dataset/test/forged/049_forg/049_forg_01.png):\n",
    "test_image_path = input(\"Enter path of signature image : \")  \n",
    "train_path = '../Dataset/Features/Training/training_'+train_person_id+'.csv' # specify path of train CSV for that requested person\n",
    "testing(test_image_path)   # make a new seperate CSV to store the features of the specific test image \n",
    "test_path = '../Dataset/TestFeatures/testcsv.csv'  # specify the path of newly created test CSV\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 7 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "n_hidden_3 = 30 # 3rd layer number of neurons\n",
    "n_classes = 2 # no. of classes (genuine or forged)\n",
    "\n",
    "# tf Graph input\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.math.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op, var_list=None)\n",
    "\n",
    "# For accuracies\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "evaluate(train_path, test_path, type2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46e260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869670a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86779a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0ee88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281d047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9f10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3f802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452972dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db5541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb9a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c7a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ea518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e0c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccb048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63866e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7982cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3277b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ca347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ecb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd13306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ed8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0050af21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eaf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf20e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a0859a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a8848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf725817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c171986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563b706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
